!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.8	//
ABCMeta	metrics/reference.py	/^from abc import ABCMeta, abstractmethod$/;"	i
ABCMeta	metrics/scorer.py	/^from abc import ABCMeta, abstractmethod$/;"	i
AGraph	hypgraph.py	/^		from pygraphviz import AGraph$/;"	i
BeerError	metrics/beer.py	/^class BeerError(Exception):$/;"	c
BeerReference	metrics/beer.py	/^class BeerReference(Reference):$/;"	c
BeerScorer	metrics/beer.py	/^class BeerScorer(Scorer):$/;"	c
BeerScorer	metrics/scorer_provider.py	/^from beer import BeerScorer$/;"	i
CharacterFScoreReference	metrics/chrf.py	/^class CharacterFScoreReference(Reference):$/;"	c
CharacterFScorer	metrics/chrf.py	/^class CharacterFScorer(Scorer):$/;"	c
CharacterFScorer	metrics/scorer_provider.py	/^from chrf import CharacterFScorer$/;"	i
CharacterFScorer	metrics/test_chrf.py	/^from chrf import CharacterFScorer$/;"	i
DomainInterpolatorTextIterator	domain_interpolation_data_iterator.py	/^class DomainInterpolatorTextIterator:$/;"	c
DomainInterpolatorTextIterator	nmt.py	/^from domain_interpolation_data_iterator import DomainInterpolatorTextIterator$/;"	i
Empty	translate.py	/^from Queue import Empty$/;"	i
HypGraph	hypgraph.py	/^class HypGraph(object):$/;"	c
HypGraph	nmt.py	/^        from hypgraph import HypGraph$/;"	i
HypGraphRenderer	hypgraph.py	/^class HypGraphRenderer(object):$/;"	c
HypGraphRenderer	translate.py	/^from hypgraph import HypGraphRenderer$/;"	i
MeteorError	metrics/meteor.py	/^class MeteorError(Exception):$/;"	c
MeteorReference	metrics/meteor.py	/^class MeteorReference(Reference):$/;"	c
MeteorScorer	metrics/meteor.py	/^class MeteorScorer(Scorer):$/;"	c
MeteorScorer	metrics/scorer_provider.py	/^from meteor import MeteorScorer$/;"	i
OrderedDict	layers.py	/^from collections import OrderedDict$/;"	i
OrderedDict	nmt.py	/^from collections import OrderedDict$/;"	i
OrderedDict	optimizers.py	/^from collections import OrderedDict$/;"	i
OrderedDict	theano_util.py	/^from collections import OrderedDict$/;"	i
Popen	nmt.py	/^from subprocess import Popen$/;"	i
Process	translate.py	/^from multiprocessing import Process, Queue$/;"	i
Queue	translate.py	/^from multiprocessing import Process, Queue$/;"	i
RandomStreams	initializers.py	/^from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams$/;"	i
RandomStreams	layers.py	/^from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams$/;"	i
RandomStreams	nmt.py	/^from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams$/;"	i
RandomStreams	optimizers.py	/^from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams$/;"	i
RandomStreams	rescore.py	/^from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams$/;"	i
RandomStreams	score.py	/^from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams$/;"	i
RandomStreams	theano_util.py	/^from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams$/;"	i
RandomStreams	translate.py	/^    from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams$/;"	i
Reference	metrics/beer.py	/^from reference import Reference$/;"	i
Reference	metrics/chrf.py	/^from reference import Reference$/;"	i
Reference	metrics/meteor.py	/^from reference import Reference$/;"	i
Reference	metrics/reference.py	/^class Reference:$/;"	c
Reference	metrics/sentence_bleu.py	/^from reference import Reference$/;"	i
Scorer	metrics/beer.py	/^from scorer import Scorer$/;"	i
Scorer	metrics/chrf.py	/^from scorer import Scorer$/;"	i
Scorer	metrics/meteor.py	/^from scorer import Scorer$/;"	i
Scorer	metrics/scorer.py	/^class Scorer:$/;"	c
Scorer	metrics/scorer_interpolator.py	/^from scorer import Scorer$/;"	i
Scorer	metrics/sentence_bleu.py	/^from scorer import Scorer$/;"	i
ScorerInterpolator	metrics/scorer_interpolator.py	/^class ScorerInterpolator(Scorer):$/;"	c
ScorerProvider	metrics/scorer_provider.py	/^class ScorerProvider:$/;"	c
ScorerProvider	metrics/test_scorer_provider.py	/^from scorer_provider import ScorerProvider$/;"	i
ScorerProvider	nmt.py	/^from metrics.scorer_provider import ScorerProvider$/;"	i
SentenceBleuReference	metrics/sentence_bleu.py	/^class SentenceBleuReference(Reference):$/;"	c
SentenceBleuScorer	metrics/scorer_provider.py	/^from sentence_bleu import SentenceBleuScorer$/;"	i
SentenceBleuScorer	metrics/sentence_bleu.py	/^class SentenceBleuScorer(Scorer):$/;"	c
SentenceBleuScorer	metrics/test_scorer_provider.py	/^from sentence_bleu import SentenceBleuScorer$/;"	i
SentenceBleuScorer	metrics/test_sentence_bleu.py	/^from sentence_bleu import SentenceBleuScorer$/;"	i
TestCharacterFScoreReference	metrics/test_chrf.py	/^class TestCharacterFScoreReference(unittest.TestCase):$/;"	c
TestScorerProvider	metrics/test_scorer_provider.py	/^class TestScorerProvider(unittest.TestCase):$/;"	c
TestSentenceBleuReference	metrics/test_sentence_bleu.py	/^class TestSentenceBleuReference(unittest.TestCase):$/;"	c
TextIterator	data_iterator.py	/^class TextIterator:$/;"	c
TextIterator	nmt.py	/^from data_iterator import TextIterator$/;"	i
TextIterator	rescore.py	/^from data_iterator import TextIterator$/;"	i
TextIterator	score.py	/^from data_iterator import TextIterator$/;"	i
TrainingProgress	nmt.py	/^from training_progress import TrainingProgress$/;"	i
TrainingProgress	training_progress.py	/^class TrainingProgress(object):$/;"	c
__author__	alignment_util.py	/^__author__ = 'canliu'$/;"	v
__init__	data_iterator.py	/^    def __init__(self, source, target,$/;"	m	class:TextIterator
__init__	domain_interpolation_data_iterator.py	/^    def __init__(self, source, target,$/;"	m	class:DomainInterpolatorTextIterator
__init__	hypgraph.py	/^	def __init__(self):$/;"	m	class:HypGraph
__init__	hypgraph.py	/^	def __init__(self, hyp_graph):$/;"	m	class:HypGraphRenderer
__init__	metrics/beer.py	/^    def __init__(self, argument_string):$/;"	m	class:BeerScorer
__init__	metrics/beer.py	/^    def __init__(self, reference_tokens, beer_scorer):$/;"	m	class:BeerReference
__init__	metrics/beer.py	/^    def __init__(self, value):$/;"	m	class:BeerError
__init__	metrics/chrf.py	/^    def __init__(self, argument_string):$/;"	m	class:CharacterFScorer
__init__	metrics/chrf.py	/^    def __init__(self, reference_tokens, n=6, beta=1):$/;"	m	class:CharacterFScoreReference
__init__	metrics/meteor.py	/^    def __init__(self, argument_string):$/;"	m	class:MeteorScorer
__init__	metrics/meteor.py	/^    def __init__(self, reference_tokens, meteor_scorer):$/;"	m	class:MeteorReference
__init__	metrics/meteor.py	/^    def __init__(self, value):$/;"	m	class:MeteorError
__init__	metrics/reference.py	/^    def __init__(self, reference_tokens):$/;"	m	class:Reference
__init__	metrics/scorer.py	/^    def __init__(self, argument_string):$/;"	m	class:Scorer
__init__	metrics/scorer_interpolator.py	/^    def __init__(self, config_string):$/;"	m	class:ScorerInterpolator
__init__	metrics/scorer_provider.py	/^    def __init__(self):$/;"	m	class:ScorerProvider
__init__	metrics/sentence_bleu.py	/^    def __init__(self, argument_string):$/;"	m	class:SentenceBleuScorer
__init__	metrics/sentence_bleu.py	/^    def __init__(self, reference_tokens, n=4):$/;"	m	class:SentenceBleuReference
__iter__	data_iterator.py	/^    def __iter__(self):$/;"	m	class:TextIterator	file:
__iter__	domain_interpolation_data_iterator.py	/^    def __iter__(self):$/;"	m	class:DomainInterpolatorTextIterator	file:
__len__	data_iterator.py	/^    def __len__(self):$/;"	m	class:TextIterator	file:
__metaclass__	metrics/reference.py	/^    __metaclass__ = ABCMeta #abstract base class$/;"	v	class:Reference
__metaclass__	metrics/scorer.py	/^    __metaclass__ = ABCMeta #abstract base class$/;"	v	class:Scorer
__str__	metrics/beer.py	/^    def __str__(self):$/;"	m	class:BeerError	file:
__str__	metrics/meteor.py	/^    def __str__(self):$/;"	m	class:MeteorError	file:
_escape_label	hypgraph.py	/^	def _escape_label(self, label):$/;"	m	class:HypGraphRenderer
_finish_processes	translate.py	/^    def _finish_processes():$/;"	f	function:main
_get_ngrams	metrics/chrf.py	/^    def _get_ngrams(self, tokens, n):$/;"	m	class:CharacterFScoreReference
_get_ngrams	metrics/sentence_bleu.py	/^    def _get_ngrams(self, tokens, max_n):$/;"	m	class:SentenceBleuReference
_highlight_best	hypgraph.py	/^	def _highlight_best(self):$/;"	m	class:HypGraphRenderer
_node_attr	hypgraph.py	/^	def _node_attr(self, node_id, costs=False, word_probs=False):	$/;"	m	class:HypGraphRenderer
_render	hypgraph.py	/^	def _render(self, costs=False, word_probs=False, highlight_best=False):	$/;"	m	class:HypGraphRenderer
_retrieve_jobs	translate.py	/^    def _retrieve_jobs(n_samples):$/;"	f	function:main
_score	rescore.py	/^    def _score(pairs, alignweights=False):$/;"	f	function:rescore_model
_score	score.py	/^    def _score(pairs, alignweights=False):$/;"	f	function:rescore_model
_send_jobs	translate.py	/^    def _send_jobs(f):$/;"	f	function:main
_seqs2words	translate.py	/^    def _seqs2words(cc):$/;"	f	function:main
_slice	layers.py	/^    def _slice(_x, n, dim):$/;"	f	function:gru_cond_layer
_slice	layers.py	/^    def _slice(_x, n, dim):$/;"	f	function:gru_layer
_step_slice	layers.py	/^    def _step_slice(*args):$/;"	f	function:gru_layer
_step_slice	layers.py	/^    def _step_slice(m_, x_, xx_, h_, ctx_, alpha_, pctx_, cc_, rec_dropout, ctx_dropout):$/;"	f	function:gru_cond_layer
_translate	translate.py	/^    def _translate(seq):$/;"	f	function:translate_model
abstractmethod	metrics/reference.py	/^from abc import ABCMeta, abstractmethod$/;"	i
abstractmethod	metrics/scorer.py	/^from abc import ABCMeta, abstractmethod$/;"	i
adadelta	optimizers.py	/^def adadelta(lr, tparams, grads, inp, cost, optimizer_params={}, profile=False):$/;"	f
adam	optimizers.py	/^def adam(lr, tparams, grads, inp, cost, beta1=0.9, beta2=0.999, e=1e-8, optimizer_params={}, profile=False):$/;"	f
add	hypgraph.py	/^	def add(self, word, history, word_prob=None, cost=None):$/;"	m	class:HypGraph
adjust_domain_interpolation_rate	domain_interpolation_data_iterator.py	/^    def adjust_domain_interpolation_rate(self, interpolation_rate):$/;"	m	class:DomainInterpolatorTextIterator
argparse	nmt.py	/^import argparse$/;"	i
argparse	rescore.py	/^import argparse$/;"	i
argparse	score.py	/^import argparse$/;"	i
argparse	translate.py	/^import argparse$/;"	i
args	nmt.py	/^    args = parser.parse_args()$/;"	v
args	rescore.py	/^    args = parser.parse_args()$/;"	v
args	score.py	/^    args = parser.parse_args()$/;"	v
brevity_penalty	metrics/sentence_bleu.py	/^        def brevity_penalty(ref_length, hyp_length):$/;"	f	function:SentenceBleuReference.score
build_decoder	nmt.py	/^def build_decoder(tparams, options, y, ctx, init_state, dropout, x_mask=None, y_mask=None, sampling=False, pctx_=None, shared_vars=None):$/;"	f
build_encoder	nmt.py	/^def build_encoder(tparams, options, dropout, x_mask=None, sampling=False):$/;"	f
build_full_sampler	nmt.py	/^def build_full_sampler(tparams, options, use_noise, trng, greedy=False):$/;"	f
build_model	nmt.py	/^def build_model(tparams, options):$/;"	f
build_model	rescore.py	/^from nmt import (pred_probs, build_model, prepare_data, init_params)$/;"	i
build_model	score.py	/^from nmt import (pred_probs, build_model, prepare_data, init_params)$/;"	i
build_sampler	nmt.py	/^def build_sampler(tparams, options, use_noise, trng, return_alignment=False):$/;"	f
build_sampler	translate.py	/^    from nmt import (build_sampler, gen_sample, init_params)$/;"	i
call	shuffle.py	/^from subprocess import call$/;"	i
choices	nmt.py	/^                         choices=['adam', 'adadelta', 'rmsprop', 'sgd', 'sgdmomentum'],$/;"	v
choices	nmt.py	/^                         choices=['gru', 'gru_cond'],$/;"	v
codecs	alignment_util.py	/^import codecs$/;"	i
combine_source_target_text	alignment_util.py	/^def combine_source_target_text(source_IN, nbest_IN, saveto, alignment_IN):$/;"	f
combine_source_target_text_1to1	alignment_util.py	/^def combine_source_target_text_1to1(source_IN, target_IN, saveto, alignment_IN):$/;"	f
concatenate	theano_util.py	/^def concatenate(tensor_list, axis=0):$/;"	f
convert_to_nodes_edges_each_v1	alignment_util.py	/^def convert_to_nodes_edges_each_v1(data):$/;"	f
convert_to_nodes_edges_each_v2	alignment_util.py	/^def convert_to_nodes_edges_each_v2(data, sent_id):$/;"	f
convert_to_nodes_edges_v1	alignment_util.py	/^def convert_to_nodes_edges_v1(filename):$/;"	f
convert_to_nodes_edges_v2	alignment_util.py	/^def convert_to_nodes_edges_v2(filename):$/;"	f
copy	nmt.py	/^import copy$/;"	i
data	nmt.py	/^    data = parser.add_argument_group('data sets; model loading and saving')$/;"	v
decoder_step	nmt.py	/^    def decoder_step(y, init_state, ctx, pctx_, *shared_vars):$/;"	f	function:build_full_sampler
defaultdict	hypgraph.py	/^from collections import defaultdict$/;"	i
defaultdict	metrics/sentence_bleu.py	/^from collections import defaultdict$/;"	i
display	nmt.py	/^    display = parser.add_argument_group('display parameters')$/;"	v
division	metrics/sentence_bleu.py	/^from __future__ import division$/;"	i
domain_interpolation	nmt.py	/^    domain_interpolation = parser.add_argument_group('domain interpolation parameters')$/;"	v
dropout_constr	layers.py	/^def dropout_constr(options, use_noise, trng, sampling):$/;"	f
embedding_layer	layers.py	/^def embedding_layer(tparams, ids, factors=None, prefix='', suffix=''):$/;"	f
embedding_name	theano_util.py	/^def embedding_name(i):$/;"	f
exp	metrics/sentence_bleu.py	/^from math import exp$/;"	i
fflayer	layers.py	/^def fflayer(tparams, state_below, options, dropout, prefix='rconv',$/;"	f
fill_options	compat.py	/^def fill_options(options):$/;"	f
fill_options	rescore.py	/^from compat import fill_options$/;"	i
fill_options	score.py	/^from compat import fill_options$/;"	i
fill_options	translate.py	/^from compat import fill_options$/;"	i
floatX	theano_util.py	/^floatX = theano.config.floatX$/;"	v
fopen	data_iterator.py	/^def fopen(filename, mode='r'):$/;"	f
fopen	domain_interpolation_data_iterator.py	/^def fopen(filename, mode='r'):$/;"	f
gen_sample	nmt.py	/^def gen_sample(f_init, f_next, x, trng=None, k=1, maxlen=30,$/;"	f
gen_sample	translate.py	/^    from nmt import (build_sampler, gen_sample, init_params)$/;"	i
get	metrics/scorer_provider.py	/^    def get(self, config_string):$/;"	m	class:ScorerProvider
get_alignments	alignment_util.py	/^def get_alignments(attention, x_mask, y_mask):$/;"	f
get_id	hypgraph.py	/^	def get_id(self, word, history):	$/;"	m	class:HypGraph
get_ids	hypgraph.py	/^	def get_ids(self, words):	$/;"	m	class:HypGraph
get_layer	layers.py	/^            def get_layer(shape, dropout_probability=0, num=1):$/;"	f	function:dropout_constr.get_layer
get_layer	layers.py	/^            def get_layer(shape=None, dropout_probability=0, num=1):$/;"	f	function:dropout_constr.get_layer
get_layer	layers.py	/^    def get_layer(shape=None, dropout_probability=0, num=1):$/;"	f	function:dropout_constr
get_layer_constr	layers.py	/^def get_layer_constr(name):$/;"	f
get_layer_param	layers.py	/^def get_layer_param(name):$/;"	f
gru_cond_layer	layers.py	/^def gru_cond_layer(tparams, state_below, options, dropout, prefix='gru',$/;"	f
gru_layer	layers.py	/^def gru_layer(tparams, state_below, options, dropout, prefix='gru',$/;"	f
gzip	data_iterator.py	/^import gzip$/;"	i
gzip	domain_interpolation_data_iterator.py	/^import gzip$/;"	i
help	nmt.py	/^                         help=" normalize weights (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="L2 regularization penalty (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="L2 regularization penalty towards original weights (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="MRT alpha (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="disable shuffling of training data (for each epoch)")$/;"	v
help	nmt.py	/^                         help="display loss after INT updates (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="display some samples after INT updates (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="don't reload training progress (only used if --reload is enabled)")$/;"	v
help	nmt.py	/^                         help="draw n independent samples to calculate mean loss (which is subtracted from loss) (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="dropout for hidden layer (0: no dropout) (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="dropout for input embeddings (0: no dropout) (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="dropout source words (0: no dropout) (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="dropout target words (0: no dropout) (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="early stopping patience (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="embedding layer size (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="gradient clipping threshold (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="hidden layer size (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="indomain parallel training corpus (source and target)")$/;"	v
help	nmt.py	/^                         help="interpolate between an out-domain training corpus and an in-domain training corpus")$/;"	v
help	nmt.py	/^                         help="interpolation increment to be applied each time patience runs out, until maximum amount of interpolation is reached (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="learning rate (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="list of word vector dimensionalities (one per factor): '--dim_per_factor 250 200 50' for total dimensionality of 500 (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="load existing model (if '--model' points to existing model)")$/;"	v
help	nmt.py	/^                         help="location of validation script (to run your favorite metric for validation) (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="maximum fraction of in-domain training data (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="maximum number of epochs (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="maximum number of updates (minibatches) (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="maximum sequence length (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="minibatch size (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="minimum (initial) fraction of in-domain training data (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="model file name (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="network vocabularies (one per source factor, plus target vocabulary)")$/;"	v
help	nmt.py	/^                         help="number of GRU transition operations applied in the encoder. Minimum is 1. (Only applies to gru). (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="number of GRU transition operations applied in the first layer of the decoder. Minimum is 2.  (Only applies to gru_cond). (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="number of GRU transition operations applied in the higher layers of the decoder. Minimum is 1. (Only applies to gru). (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="number of bidirectional encoder layer; if enc_depth is greater, remaining layers are unidirectional; by default, all layers are bidirectional.")$/;"	v
help	nmt.py	/^                         help="number of decoder layers (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="number of encoder layers (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="number of input factors (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="optimizer (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="parallel training corpus (source and target)")$/;"	v
help	nmt.py	/^                         help="parallel validation corpus (source and target) (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="pass context vector (from first layer) to deep decoder layers")$/;"	v
help	nmt.py	/^                         help="samples per source sentence (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="save frequency (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="source vocabulary size (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="target vocabulary size (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="tie the input embeddings of the decoder with the softmax output embeddings")$/;"	v
help	nmt.py	/^                         help="tie the input embeddings of the encoder and the decoder (first factor only). Source and target vocabulary size must the same")$/;"	v
help	nmt.py	/^                         help="truncate BPTT gradients in the encoder to this value. Use -1 for no truncation (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="use dropout layer (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="use layer normalisation (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="validation frequency (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="validation minibatch size (default: %(default)s)")$/;"	v
help	nmt.py	/^                         help="write all models to same file")$/;"	v
help	nmt.py	/^                         help='add reference to MRT samples.')$/;"	v
help	nmt.py	/^                         help='decoder recurrent layer after first one')$/;"	v
help	nmt.py	/^                         help='do not sort sentences in maxibatch by length')$/;"	v
help	nmt.py	/^                         help='loss used in MRT (default: %(default)s)')$/;"	v
help	nmt.py	/^                         help='size of maxibatch (number of minibatches that are sorted by length) (default: %(default)s)')$/;"	v
help	nmt.py	/^                         help='training objective. CE: cross-entropy minimization (default); MRT: Minimum Risk Training (https:\/\/www.aclweb.org\/anthology\/P\/P16\/P16-1159.pdf)')$/;"	v
help	nmt.py	/^                     help="mix in ML objective in MRT training with this scaling factor (default: %(default)s)")$/;"	v
help	rescore.py	/^                        help="Input n-best list file (default: standard input)")$/;"	v
help	rescore.py	/^                        help="Minibatch size (default: %(default)s))")$/;"	v
help	rescore.py	/^                        help="Normalize scores by sentence length (with argument, exponentiate lengths by ALPHA)")$/;"	v
help	rescore.py	/^                        help="Output file (default: standard output)")$/;"	v
help	rescore.py	/^                        help="Source text file")$/;"	v
help	rescore.py	/^                        help="Whether to store the alignment weights or not. If specified, weights will be saved in <input>.alignment")$/;"	v
help	rescore.py	/^                        help="model to use. Provide multiple models (with same vocabulary) for ensemble decoding")$/;"	v
help	score.py	/^                        help="Minibatch size (default: %(default)s))")$/;"	v
help	score.py	/^                        help="Normalize scores by sentence length (with argument, exponentiate lengths by ALPHA)")$/;"	v
help	score.py	/^                        help="Output file (default: standard output)")$/;"	v
help	score.py	/^                        help="Source text file")$/;"	v
help	score.py	/^                        help="Target text file")$/;"	v
help	score.py	/^                        help="Whether to store the alignment weights or not. If specified, weights will be saved in <target>.alignment")$/;"	v
help	score.py	/^                        help="model to use. Provide multiple models (with same vocabulary) for ensemble decoding")$/;"	v
indomain_reset	domain_interpolation_data_iterator.py	/^    def indomain_reset(self):$/;"	m	class:DomainInterpolatorTextIterator
init_params	nmt.py	/^def init_params(options):$/;"	f
init_params	rescore.py	/^from nmt import (pred_probs, build_model, prepare_data, init_params)$/;"	i
init_params	score.py	/^from nmt import (pred_probs, build_model, prepare_data, init_params)$/;"	i
init_params	translate.py	/^    from nmt import (build_sampler, gen_sample, init_params)$/;"	i
init_theano_params	rescore.py	/^from theano_util import (load_params, init_theano_params)$/;"	i
init_theano_params	score.py	/^from theano_util import (load_params, init_theano_params)$/;"	i
init_theano_params	theano_util.py	/^def init_theano_params(params):$/;"	f
init_theano_params	translate.py	/^    from theano_util import (load_params, init_theano_params)$/;"	i
input_file	alignment_util.py	/^    input_file = sys.argv[1]$/;"	v
itemlist	theano_util.py	/^def itemlist(tparams):$/;"	f
itertools	nmt.py	/^import itertools$/;"	i
json	alignment_util.py	/^import json$/;"	i
json	layers.py	/^import json$/;"	i
json	nmt.py	/^import json$/;"	i
json	rescore.py	/^import json$/;"	i
json	score.py	/^import json$/;"	i
json	theano_util.py	/^import json$/;"	i
json	training_progress.py	/^import json$/;"	i
json	translate.py	/^import json$/;"	i
json	util.py	/^import json$/;"	i
kill_process	metrics/beer.py	/^    def kill_process(self):$/;"	m	class:BeerScorer
kill_process	metrics/meteor.py	/^    def kill_process(self):$/;"	m	class:MeteorScorer
layer_norm	layers.py	/^def layer_norm(x, b, s):$/;"	f
layers	layers.py	/^layers = {'ff': ('param_init_fflayer', 'fflayer'),$/;"	v
linear	theano_util.py	/^def linear(x):$/;"	f
load_config	rescore.py	/^from util import load_dict, load_config$/;"	i
load_config	score.py	/^from util import load_dict, load_config$/;"	i
load_config	translate.py	/^from util import load_dict, load_config$/;"	i
load_config	util.py	/^def load_config(basename):$/;"	f
load_dict	data_iterator.py	/^from util import load_dict$/;"	i
load_dict	domain_interpolation_data_iterator.py	/^from util import load_dict$/;"	i
load_dict	rescore.py	/^from util import load_dict, load_config$/;"	i
load_dict	score.py	/^from util import load_dict, load_config$/;"	i
load_dict	translate.py	/^from util import load_dict, load_config$/;"	i
load_dict	util.py	/^def load_dict(filename):$/;"	f
load_from_json	training_progress.py	/^    def load_from_json(self, file_name):$/;"	m	class:TrainingProgress
load_optimizer_params	theano_util.py	/^def load_optimizer_params(path, optimizer_name):$/;"	f
load_params	rescore.py	/^from theano_util import (load_params, init_theano_params)$/;"	i
load_params	score.py	/^from theano_util import (load_params, init_theano_params)$/;"	i
load_params	theano_util.py	/^def load_params(path, params, with_prefix=''):$/;"	f
load_params	translate.py	/^    from theano_util import (load_params, init_theano_params)$/;"	i
main	rescore.py	/^def main(models, source_file, nbest_file, saveto, b=80,$/;"	f
main	score.py	/^def main(models, source_file, nbest_file, saveto, b=80,$/;"	f
main	shuffle.py	/^def main(files, temporary=False):$/;"	f
main	translate.py	/^def main(models, source_file, saveto, save_alignment=None, k=5,$/;"	f
math	domain_interpolation_data_iterator.py	/^import math$/;"	i
mrt	nmt.py	/^    mrt = parser.add_argument_group('minimum risk training parameters')$/;"	v
mrt_cost	nmt.py	/^def mrt_cost(cost, y_mask, options):$/;"	f
mul	metrics/sentence_bleu.py	/^from operator import mul$/;"	i
network	nmt.py	/^    network = parser.add_argument_group('network parameters')$/;"	v
next	data_iterator.py	/^    def next(self):$/;"	m	class:TextIterator
next	domain_interpolation_data_iterator.py	/^    def next(self):$/;"	m	class:DomainInterpolatorTextIterator
ngram_precisions	metrics/sentence_bleu.py	/^        def ngram_precisions(ref_ngrams, hyp_ngrams):$/;"	f	function:SentenceBleuReference.score
norm_weight	initializers.py	/^def norm_weight(nin, nout=None, scale=0.01, ortho=True):$/;"	f
numpy	data_iterator.py	/^import numpy$/;"	i
numpy	domain_interpolation_data_iterator.py	/^import numpy$/;"	i
numpy	initializers.py	/^import numpy$/;"	i
numpy	layers.py	/^import numpy$/;"	i
numpy	nmt.py	/^import numpy$/;"	i
numpy	optimizers.py	/^import numpy$/;"	i
numpy	rescore.py	/^import numpy$/;"	i
numpy	score.py	/^import numpy$/;"	i
numpy	theano_util.py	/^import numpy$/;"	i
numpy	translate.py	/^import numpy$/;"	i
numpy_floatX	theano_util.py	/^numpy_floatX = numpy.typeDict[floatX]$/;"	v
ortho_weight	initializers.py	/^def ortho_weight(ndim):$/;"	f
os	nmt.py	/^import os$/;"	i
os	shuffle.py	/^import os$/;"	i
os	translate.py	/^        import os$/;"	i
param_init_embedding_layer	layers.py	/^def param_init_embedding_layer(options, params, n_words, dims, factors=None, prefix='', suffix=''):$/;"	f
param_init_fflayer	layers.py	/^def param_init_fflayer(options, params, prefix='ff', nin=None, nout=None,$/;"	f
param_init_gru	layers.py	/^def param_init_gru(options, params, prefix='gru', nin=None, dim=None,$/;"	f
param_init_gru_cond	layers.py	/^def param_init_gru_cond(options, params, prefix='gru_cond',$/;"	f
parser	nmt.py	/^    parser = argparse.ArgumentParser()$/;"	v
parser	rescore.py	/^    parser = argparse.ArgumentParser()$/;"	v
parser	score.py	/^    parser = argparse.ArgumentParser()$/;"	v
pkl	layers.py	/^import cPickle as pkl$/;"	i
pkl	nmt.py	/^import cPickle as pkl$/;"	i
pkl	theano_util.py	/^import cPickle as pkl$/;"	i
pkl	translate.py	/^import cPickle as pkl$/;"	i
pkl	util.py	/^import cPickle as pkl$/;"	i
pp	theano_util.py	/^def pp(pp, name):$/;"	f
pred_probs	nmt.py	/^def pred_probs(f_log_probs, prepare_data, options, iterator, verbose=True, normalization_alpha=0.0, alignweights=False):$/;"	f
pred_probs	rescore.py	/^from nmt import (pred_probs, build_model, prepare_data, init_params)$/;"	i
pred_probs	score.py	/^from nmt import (pred_probs, build_model, prepare_data, init_params)$/;"	i
prepare_data	nmt.py	/^def prepare_data(seqs_x, seqs_y, maxlen=None, n_words_src=30000,$/;"	f
prepare_data	rescore.py	/^from nmt import (pred_probs, build_model, prepare_data, init_params)$/;"	i
prepare_data	score.py	/^from nmt import (pred_probs, build_model, prepare_data, init_params)$/;"	i
print_matrices	translate.py	/^def print_matrices(mm, file):$/;"	f
print_matrix	translate.py	/^def print_matrix(hyp, file):$/;"	f
print_matrix_json	translate.py	/^def print_matrix_json(hyp, source, target, sid, tid, file):$/;"	f
product	metrics/sentence_bleu.py	/^        def product(iterable):$/;"	f	function:SentenceBleuReference.score
profile	nmt.py	/^profile = False$/;"	v
random	shuffle.py	/^import random$/;"	i
rescore	__init__.py	/^import rescore$/;"	i
rescore_model	rescore.py	/^def rescore_model(source_file, nbest_file, saveto, models, options, b, normalization_alpha, verbose, alignweights):$/;"	f
rescore_model	score.py	/^def rescore_model(source_file, target_file, saveto, models, options, b, normalization_alpha, verbose, alignweights):$/;"	f
reset	data_iterator.py	/^    def reset(self):$/;"	m	class:TextIterator
reset	domain_interpolation_data_iterator.py	/^    def reset(self):$/;"	m	class:DomainInterpolatorTextIterator
rmsprop	optimizers.py	/^def rmsprop(lr, tparams, grads, inp, cost, optimizer_params={}, profile=False):$/;"	f
save_png	hypgraph.py	/^	def save_png(self, filepath, detailed=False, highlight_best=False):$/;"	m	class:HypGraphRenderer
save_to_json	training_progress.py	/^    def save_to_json(self, file_name):$/;"	m	class:TrainingProgress
score	metrics/beer.py	/^    def score(self, hypothesis_tokens):$/;"	m	class:BeerReference
score	metrics/chrf.py	/^    def score(self, hypothesis_tokens):$/;"	m	class:CharacterFScoreReference
score	metrics/meteor.py	/^    def score(self, hypothesis_tokens):$/;"	m	class:MeteorReference
score	metrics/reference.py	/^    def score(self, hypothesis_tokens):$/;"	m	class:Reference
score	metrics/scorer.py	/^    def score(self, hypothesis_tokens):$/;"	m	class:Scorer
score	metrics/scorer_interpolator.py	/^    def score(self, hypothesis_tokens):$/;"	m	class:ScorerInterpolator
score	metrics/sentence_bleu.py	/^    def score(self, hypothesis_tokens):$/;"	m	class:SentenceBleuReference
score_matrix	metrics/reference.py	/^    def score_matrix(self, hypothesis_matrix):$/;"	m	class:Reference
score_matrix	metrics/scorer.py	/^    def score_matrix(self, hypothesis_matrix):$/;"	m	class:Scorer
score_matrix	metrics/scorer_interpolator.py	/^    def score_matrix(self, hypothesis_matrix):$/;"	m	class:ScorerInterpolator
seqs2words	util.py	/^def seqs2words(seq, inverse_target_dictionary):$/;"	f
set_reference	metrics/beer.py	/^    def set_reference(self, reference_tokens):$/;"	m	class:BeerScorer
set_reference	metrics/chrf.py	/^    def set_reference(self, reference_tokens):$/;"	m	class:CharacterFScorer
set_reference	metrics/meteor.py	/^    def set_reference(self, reference_tokens):$/;"	m	class:MeteorScorer
set_reference	metrics/scorer.py	/^    def set_reference(self, reference_tokens):$/;"	m	class:Scorer
set_reference	metrics/scorer_interpolator.py	/^    def set_reference(self, reference_tokens):$/;"	m	class:ScorerInterpolator
set_reference	metrics/sentence_bleu.py	/^    def set_reference(self, reference_tokens):$/;"	m	class:SentenceBleuScorer
sgd	optimizers.py	/^def sgd(lr, tparams, grads, inp, cost, optimizer_params=None, profile=False):$/;"	f
sgdmomentum	optimizers.py	/^def sgdmomentum(lr, tparams, grads, inp, cost, momentum=0.9, optimizer_params={}, profile=False):$/;"	f
shared	translate.py	/^    from theano import shared$/;"	i
shared_dropout_layer	layers.py	/^def shared_dropout_layer(shape, use_noise, trng, value, scaled=True):$/;"	f
shuffle	data_iterator.py	/^import shuffle$/;"	i
shuffle	domain_interpolation_data_iterator.py	/^import shuffle$/;"	i
si	metrics/scorer_provider.py	/^import scorer_interpolator as si$/;"	i
sp	metrics/scorer_interpolator.py	/^import scorer_provider as sp$/;"	i
subprocess	metrics/beer.py	/^import subprocess, threading$/;"	i
subprocess	metrics/meteor.py	/^import subprocess, threading$/;"	i
sys	alignment_util.py	/^    import sys$/;"	i
sys	alignment_util.py	/^import sys$/;"	i
sys	nmt.py	/^import sys$/;"	i
sys	rescore.py	/^import sys$/;"	i
sys	score.py	/^import sys$/;"	i
sys	shuffle.py	/^import sys$/;"	i
sys	training_progress.py	/^import sys$/;"	i
sys	translate.py	/^import sys$/;"	i
sys	util.py	/^import sys$/;"	i
tanh	theano_util.py	/^def tanh(x):$/;"	f
tempfile	rescore.py	/^import tempfile$/;"	i
tempfile	score.py	/^import tempfile$/;"	i
tempfile	shuffle.py	/^import tempfile$/;"	i
tensor	initializers.py	/^import theano.tensor as tensor$/;"	i
tensor	layers.py	/^import theano.tensor as tensor$/;"	i
tensor	nmt.py	/^import theano.tensor as tensor$/;"	i
tensor	optimizers.py	/^import theano.tensor as tensor$/;"	i
tensor	theano_util.py	/^import theano.tensor as tensor$/;"	i
terminate_process	metrics/beer.py	/^    def terminate_process(self):$/;"	m	class:BeerScorer
terminate_process	metrics/meteor.py	/^    def terminate_process(self):$/;"	m	class:MeteorScorer
test_almost_correct	metrics/test_chrf.py	/^    def test_almost_correct(self):$/;"	m	class:TestCharacterFScoreReference
test_clipping	metrics/test_sentence_bleu.py	/^    def test_clipping(self):$/;"	m	class:TestSentenceBleuReference
test_completely_different_segments	metrics/test_chrf.py	/^    def test_completely_different_segments(self):$/;"	m	class:TestCharacterFScoreReference
test_completely_different_segments	metrics/test_sentence_bleu.py	/^    def test_completely_different_segments(self):$/;"	m	class:TestSentenceBleuReference
test_empty_string	metrics/test_chrf.py	/^    def test_empty_string(self):$/;"	m	class:TestCharacterFScoreReference
test_empty_string_one_character	metrics/test_chrf.py	/^    def test_empty_string_one_character(self):$/;"	m	class:TestCharacterFScoreReference
test_half_right	metrics/test_chrf.py	/^    def test_half_right(self):$/;"	m	class:TestCharacterFScoreReference
test_identical_segments	metrics/test_chrf.py	/^    def test_identical_segments(self):$/;"	m	class:TestCharacterFScoreReference
test_identical_segments	metrics/test_sentence_bleu.py	/^    def test_identical_segments(self):$/;"	m	class:TestSentenceBleuReference
test_interpolated_metrics	metrics/test_scorer_provider.py	/^    def test_interpolated_metrics(self):$/;"	m	class:TestScorerProvider
test_one_character	metrics/test_chrf.py	/^    def test_one_character(self):$/;"	m	class:TestCharacterFScoreReference
test_one_character_empty_string	metrics/test_chrf.py	/^    def test_one_character_empty_string(self):$/;"	m	class:TestCharacterFScoreReference
test_single_metric	metrics/test_scorer_provider.py	/^    def test_single_metric(self):$/;"	m	class:TestScorerProvider
theano	initializers.py	/^import theano$/;"	i
theano	initializers.py	/^import theano.tensor as tensor$/;"	i
theano	layers.py	/^import theano$/;"	i
theano	layers.py	/^import theano.tensor as tensor$/;"	i
theano	nmt.py	/^import theano$/;"	i
theano	nmt.py	/^import theano.tensor as tensor$/;"	i
theano	optimizers.py	/^import theano$/;"	i
theano	optimizers.py	/^import theano.tensor as tensor$/;"	i
theano	rescore.py	/^import theano$/;"	i
theano	score.py	/^import theano$/;"	i
theano	theano_util.py	/^import theano$/;"	i
theano	theano_util.py	/^import theano.tensor as tensor$/;"	i
threading	metrics/beer.py	/^import subprocess, threading$/;"	i
threading	metrics/meteor.py	/^import subprocess, threading$/;"	i
time	nmt.py	/^import time$/;"	i
tokenize	metrics/test_chrf.py	/^    def tokenize(sentence):$/;"	m	class:TestCharacterFScoreReference
tokenize	metrics/test_scorer_provider.py	/^    def tokenize(sentence):$/;"	m	class:TestScorerProvider
tokenize	metrics/test_sentence_bleu.py	/^    def tokenize(sentence):$/;"	m	class:TestSentenceBleuReference
train	nmt.py	/^def train(dim_word=512,  # word vector dimensionality$/;"	f
training	nmt.py	/^    training = parser.add_argument_group('training parameters')$/;"	v
translate	__init__.py	/^import translate/;"	i
translate_model	translate.py	/^def translate_model(queue, rqueue, pid, models, options, k, normalization_alpha, verbose, nbest, return_alignment, suppress_unk, return_hyp_graph, deviceid):$/;"	f
unicode_to_utf8	util.py	/^def unicode_to_utf8(d):$/;"	f
unittest	metrics/test_chrf.py	/^import unittest$/;"	i
unittest	metrics/test_scorer_provider.py	/^import unittest$/;"	i
unittest	metrics/test_sentence_bleu.py	/^import unittest$/;"	i
unzip_from_theano	theano_util.py	/^def unzip_from_theano(zipped, excluding_prefix=None):$/;"	f
util	training_progress.py	/^import util$/;"	i
validation	nmt.py	/^    validation = parser.add_argument_group('validation parameters')$/;"	v
weight_norm	layers.py	/^def weight_norm(W, s):$/;"	f
wn	layers.py	/^    def wn(param_name):$/;"	f	function:gru_cond_layer
wn	layers.py	/^    def wn(param_name):$/;"	f	function:gru_layer
wordify	hypgraph.py	/^	def wordify(self, word_dict):$/;"	m	class:HypGraphRenderer
zero_all	theano_util.py	/^def zero_all(params):$/;"	f
zip_to_theano	theano_util.py	/^def zip_to_theano(params, tparams):$/;"	f
